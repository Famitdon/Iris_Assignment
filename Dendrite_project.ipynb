{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b355ce26-5f9c-4a05-8613-89ebf8562cc9",
   "metadata": {},
   "source": [
    "# Dendrite.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672766af-7c08-45c4-946b-59d38af08337",
   "metadata": {},
   "source": [
    "### SUBMITED BY : FAMIT DONGARWAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f9bfc-ae1c-48e7-829c-520ce492b781",
   "metadata": {},
   "source": [
    "#### Assignment for the Data Science Internship opening at Dendrite.ai, an AI/ML startup!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408690d-186b-4eef-83cc-389b9f479df4",
   "metadata": {},
   "source": [
    "### Without parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1969d47a-7403-4349-8c4a-b033338cffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first five rows of the dataset:\n",
      "    sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "\n",
      "Dataset Information:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "\n",
      "Statistical Summary:\n",
      "        sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "\n",
      "Count of Missing Values in Each Column:\n",
      " sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "\n",
      "Distribution of Species in the Dataset:\n",
      " species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performance of Logistic Regression:\n",
      "Accuracy: 0.9333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "Performance of Decision Tree:\n",
      "Accuracy: 0.9333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "Performance of Random Forest:\n",
      "Accuracy: 0.9333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "Performance of Support Vector Machine:\n",
      "Accuracy: 0.9666666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Optimal Parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "\n",
      "Performance of Tuned Random Forest:\n",
      "Accuracy: 0.9333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "Model Performance Comparison:\n",
      "Logistic Regression: 0.9333\n",
      "Decision Tree: 0.9333\n",
      "Random Forest: 0.9333\n",
      "Support Vector Machine: 0.9667\n",
      "\n",
      "The Best Performing Model is: Support Vector Machine with an Accuracy of: 0.9667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "\n",
    "# Suppress any warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading Iris dataset\n",
    "iris_data = pd.read_csv('iris.csv')\n",
    "\n",
    "# Exploring the dataset\n",
    "# Take a look at the first five rows to understand its structure\n",
    "print(\"Here are the first five rows of the dataset:\\n\", iris_data.head())\n",
    "\n",
    "# Summary of the dataset's structure and data types\n",
    "print(\"\\nDataset Information:\\n\")\n",
    "iris_data.info()\n",
    "\n",
    "# Summary statistics for numerical features\n",
    "print(\"\\nStatistical Summary:\\n\", iris_data.describe())\n",
    "\n",
    "# Check for any missing values in the dataset\n",
    "print(\"\\nCount of Missing Values in Each Column:\\n\", iris_data.isnull().sum())\n",
    "\n",
    "# Check how many samples we have for each species\n",
    "print(\"\\nDistribution of Species in the Dataset:\\n\", iris_data['species'].value_counts())\n",
    "\n",
    "# Prepare the data for modeling\n",
    "# Convert the categorical target variable (species) into numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "iris_data['species'] = label_encoder.fit_transform(iris_data['species'])\n",
    "\n",
    "# Separate the features \"X\" from the target variable \"y\"\n",
    "features = iris_data.drop('species', axis=1)  # All columns except 'species'\n",
    "target = iris_data['species']  # The 'species' column\n",
    "\n",
    "# Standardize the feature values to have a mean of 0 and a standard deviation of 1\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# We will use 80% of the data for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "# Train various classification models\n",
    "# We will evaluate several different algorithms to see which performs best\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "\n",
    "# Dictionary to store the accuracy of each model\n",
    "model_performance = {}\n",
    "\n",
    "# Train each model and evaluate its performance\n",
    "for model_name, model_instance in classification_models.items():\n",
    "    model_instance.fit(X_train, y_train)  # Train the model\n",
    "    predictions = model_instance.predict(X_test)  # Make predictions on the test set\n",
    "    accuracy = accuracy_score(y_test, predictions)  # Calculate accuracy\n",
    "    model_performance[model_name] = accuracy  # Store the accuracy\n",
    "    print(f\"\\nPerformance of {model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "\n",
    "# Fine-tune the best model (Random Forest)\n",
    "# We will perform hyperparameter tuning to improve the Random Forest model\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [10, 50, 100],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10]  # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters found during tuning\n",
    "print(\"\\nOptimal Parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "best_rf_model = rf_grid_search.best_estimator_  # Get the best model\n",
    "rf_predictions = best_rf_model.predict(X_test)  # Make predictions with the tuned model\n",
    "print(\"\\nPerformance of Tuned Random Forest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "\n",
    "# Compare the performance of all models\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "for model_name, accuracy in model_performance.items():\n",
    "    print(f\"{model_name}: {accuracy:.4f}\")\n",
    "\n",
    "# Include the tuned Random Forest in the performance comparison\n",
    "model_performance['Tuned Random Forest'] = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "# Identify the model with the highest accuracy\n",
    "best_model_name = max(model_performance, key=model_performance.get)\n",
    "best_model_accuracy = model_performance[best_model_name]\n",
    "\n",
    "# Display the best model and its accuracy\n",
    "print(f\"\\nThe Best Performing Model is: {best_model_name} with an Accuracy of: {best_model_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1dfa8-d046-44b0-b6fc-70b0a273c651",
   "metadata": {},
   "source": [
    "### With parse and classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbea7a2b-663c-4afe-9ed2-072e28177c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...!\n",
      "Preprocessing the data... Getting it ready for analysis...!\n",
      "Splitting the data into training and testing sets...!\n",
      "Training and evaluating classifiers...!\n",
      "Results for Random Forest:\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Results for Decision Tree:\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Results for Naive Bayes:\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Training the best model (Random Forest) and saving predictions...\n",
      "Predictions saved to prediction1.json.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Loading our dataset, both CSV and JSON formats.\n",
    "def load_data(file_path):\n",
    "    if file_path.endswith('.json'):\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "# Function to help us save our predictions for a JSON file.\n",
    "def save_predictions(file_path, true_labels, predicted_labels):\n",
    "    results = {\n",
    "        \"true_labels\": true_labels.tolist(),\n",
    "        \"predicted_labels\": predicted_labels.tolist()\n",
    "    }\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "# Get data ready for analysis.\n",
    "def preprocess_data(df):\n",
    "    features = df.iloc[:, :-1]  # All columns except the last one for features\n",
    "    target = df.iloc[:, -1]      # Last column is target variable\n",
    "\n",
    "    # We need to convert the target variable into numbers so our models can understand it.\n",
    "    label_encoder = LabelEncoder()\n",
    "    target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "    # Standardize features so they all have a similar scale.\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    return features_scaled, target_encoded, label_encoder\n",
    "\n",
    "# Train and evaluate a few different classifiers.\n",
    "def evaluate_classifiers(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Naive Bayes\": GaussianNB()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)  # Train the model on the training data\n",
    "        predictions = model.predict(X_test)  # Make predictions on the test data\n",
    "        accuracy = accuracy_score(y_test, predictions)  # Calculate accuracy\n",
    "        results[model_name] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"report\": classification_report(y_test, predictions, output_dict=True)\n",
    "        }\n",
    "        print(f\"Results for {model_name}:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(classification_report(y_test, predictions))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main function.\n",
    "def main():\n",
    "    dataset_path = \"iris.csv\"\n",
    "    print(\"Loading the dataset...!\")\n",
    "    data = load_data(dataset_path)\n",
    "\n",
    "    print(\"Preprocessing the data... Getting it ready for analysis...!\")\n",
    "    X, y, label_encoder = preprocess_data(data)\n",
    "\n",
    "    print(\"Splitting the data into training and testing sets...!\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"Training and evaluating classifiers...!\")\n",
    "    results = evaluate_classifiers(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Save the predictions from the best model, which we'll assume is Random Forest for now.\n",
    "    print(\"Training the best model (Random Forest) and saving predictions...\")\n",
    "    best_model = RandomForestClassifier(random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    save_predictions(\"prediction1.json\", label_encoder.inverse_transform(y_test), label_encoder.inverse_transform(predictions))\n",
    "    print(\"Predictions saved to prediction1.json.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df29fd-77b5-4032-a663-43e4c2ad9f4f",
   "metadata": {},
   "source": [
    "### For regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefcc2b4-8c36-4923-9da5-c48847086ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Mean Squared Error: 0.0293, R^2 Score: 0.9538\n",
      "Random Forest Regressor - Mean Squared Error: 0.0363, R^2 Score: 0.9429\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "import json\n",
    "\n",
    "# Loading a CSV file into a pandas DataFrame.\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Prepare the dataset for modeling by handling categorical variables and scaling numerical features.   \n",
    "def prepare_data(df, target_col, task_type):\n",
    "    features = df.drop(columns=[target_col]) # Separate features and target variable\n",
    "    target = df[target_col]\n",
    "\n",
    "    # Convert categorical variables into dummy variables\n",
    "    features = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "    # Encode the target variable\n",
    "    encoder = None\n",
    "    if task_type == \"classification\":\n",
    "        encoder = LabelEncoder()\n",
    "        target = encoder.fit_transform(target)\n",
    "\n",
    "    # Scale the numerical features to have a mean of 0 and a standard deviation of 1\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target, encoder\n",
    "\n",
    "# Train various models and evaluate their performance\n",
    "def fit_and_evaluate_models(X_train, X_test, y_train, y_test, task_type):\n",
    "    # Define the models\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
    "    } if task_type == \"regression\" else {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf if task_type == \"regression\" else 0\n",
    "\n",
    "    # Loop through each model, train and evaluate its performance\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        if task_type == \"regression\":\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "            print(f\"{model_name} - Mean Squared Error: {mse:.4f}, R^2 Score: {r2:.4f}\")\n",
    "\n",
    "            if r2 > best_score:\n",
    "                best_score = r2\n",
    "                best_model = model\n",
    "        else:  # classification\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            print(f\"{model_name} - Accuracy: {accuracy:.4f}\")\n",
    "            print(classification_report(y_test, predictions))\n",
    "\n",
    "            if accuracy > best_score:\n",
    "                best_score = accuracy\n",
    "                best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Save the actual and predicted values to a JSON file\n",
    "def export_predictions_to_json(filename, actual, predicted, encoder=None):\n",
    "    results = {\n",
    "        \"actual_values\": actual.tolist(),\n",
    "        \"predicted_values\": predicted.tolist(),\n",
    "    }\n",
    "\n",
    "    # As we have an encoder, we can also save the original labels\n",
    "    if encoder:\n",
    "        results[\"actual_labels\"] = encoder.inverse_transform(actual).tolist()\n",
    "        results[\"predicted_labels\"] = encoder.inverse_transform(predicted).tolist()\n",
    "\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json.dump(results, json_file)\n",
    "\n",
    "# Function to run the entire data processing and modeling pipeline.\n",
    "def run_pipeline():\n",
    "    data_file = \"iris.csv\"  # Dataset path\n",
    "    target_variable = \"petal_width\"  # Target variable\n",
    "    task = \"regression\"\n",
    "\n",
    "    # Loading dataset\n",
    "    dataset = load_data(data_file)\n",
    "\n",
    "    # Prepare data for modeling\n",
    "    features, target, label_encoder = prepare_data(dataset, target_variable, task)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train models and find the best one\n",
    "    best_model = fit_and_evaluate_models(X_train, X_test, y_train, y_test, task)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    # Save the predictions to a JSON file\n",
    "    export_predictions_to_json(\"prediction2.json\", y_test, predictions, label_encoder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
